{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999, 785)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Functions import kNN as kNN\n",
    "#load data\n",
    "train_digits = pd.read_csv(\"data/mnist_train.csv\")\n",
    "test_digits = pd.read_csv(\"data/mnist_test.csv\")\n",
    "#convert pandas Data Frame to Numpy Array\n",
    "train_array = train_digits.to_numpy()\n",
    "test_array = test_digits.to_numpy()\n",
    "# Datensatz hat 59999 Zeilen\n",
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show image \n",
    "def return_label(sample):\n",
    "    return train_array[sample-1, 0]\n",
    "\n",
    "def show_digit(sample):\n",
    "    img = train_array[sample-1, 1:]\n",
    "    img.shape = (28,28)\n",
    "    plt.imshow(img, 'gray')\n",
    "\n",
    "print(return_label(79))\n",
    "show_digit(79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute average intensities of all rows describing the same number\n",
    "#imshow as output\n",
    "def avg_digit_img(dat, digit):\n",
    "\n",
    "    #create list with rowindex for given digit\n",
    "    list_digit = []\n",
    "    for i in range(0, dat.shape[0]):\n",
    "        if dat[i, 0] == digit:\n",
    "            list_digit.append(i)\n",
    "\n",
    "    #create np array filled with zeros in shape flat image\n",
    "    avg = np.zeros((1,784))\n",
    "    \n",
    "    #sum up intensities from all selected images for every pixel\n",
    "    for j in range(0, len(list_digit)):\n",
    "        avg += dat[list_digit[j], 1:]\n",
    "    #shape image\n",
    "    avg.shape = (28,28)\n",
    "    #divide by number of selected pictures for average intensity value\n",
    "    avg /= len(list_digit)\n",
    "\n",
    "    #show image and colorbar\n",
    "    plt.imshow(avg, 'gray')\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare sample image with averaged images pixel by pixel\n",
    "#select digit with lowest difference in intensity (output)\n",
    "def digit_recognition(sample):\n",
    "\n",
    "    intensities_list = [] #will be filled with average intensity differences for each digit \n",
    "    sample_img = test_array[sample-1, 1:] #create array with intensity values of sample\n",
    "\n",
    "    #subtract avg array from sample array and store as difference array (diff_arr)\n",
    "    for i in range(0,10):\n",
    "        diff_arr = sample_img - avg_digit_arr(train_array, i)\n",
    "        \n",
    "        #turn difference array to difference list\n",
    "        diff_list = []\n",
    "        for j in range(0, 784):\n",
    "            diff_list.append(diff_arr[0, j])\n",
    "\n",
    "        #sum all absolute values of difference list and assign to variable intensity_sum\n",
    "        intensity_sum = 0\n",
    "        for k in range(0, len(diff_list)):\n",
    "            diff_list[k] = diff_list[k]**2\n",
    "            diff_list[k] = np.sqrt(diff_list[k])\n",
    "            intensity_sum += diff_list[k]\n",
    "\n",
    "        #append intensities_list by intensity sum\n",
    "        #at the end of for loop, intensites_list contains 1 value for each of the 10 digits\n",
    "        intensities_list.append(intensity_sum)\n",
    "\n",
    "    #select smallest value and return as output\n",
    "    return intensities_list.index(min(intensities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intensit√§tsdifferenzen zwischen n-tem Pixel von allen Bildern aufaddieren\n",
    "intensities_diff = np.zeros((1, 784))\n",
    "for i in range(0, 10000):\n",
    "    for j in range(0, 10000):\n",
    "        if i != j:\n",
    "            intensities_diff += np.sqrt((train_array[i, 1:785] - train_array[j, 1:785])**2)\n",
    "\n",
    "#array in liste\n",
    "intensities_diff_list = []\n",
    "for k in range(0, 784):\n",
    "    intensities_diff_list.append(intensities_diff[0, k])\n",
    "\n",
    "#anteile jedes pixels berechnen\n",
    "weighting_list = []\n",
    "for m in range(0,784):\n",
    "    weighting_list.append(intensities_diff_list[m]/sum(intensities_diff_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84\n",
      " 252 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253\n",
      " 228  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0\n",
      "   0   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0\n",
      "   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255\n",
      " 253 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0\n",
      "   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0\n",
      "   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7\n",
      " 135 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223\n",
      "   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48\n",
      " 165 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86\n",
      " 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225\n",
      " 253 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252\n",
      " 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11416059 0.35882197 0.52767727 0.28041646\n",
      " 0.06615868 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.15791515\n",
      " 0.81036897 0.85918737 0.82558865 0.74263472 0.57423711 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.19194906 0.82914683 0.93141195 0.92485091\n",
      " 0.87013345 0.81414211 0.78853989 0.14177427 0.01079365 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.03364067 0.21341672\n",
      " 0.81200452 0.91385866 0.91545358 0.91456726 0.73577474 0.30372355\n",
      " 0.86945008 0.75791391 0.28094147 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.58125833 0.91719471 0.92100181 0.92110483\n",
      " 0.91997747 0.91686859 0.92053216 0.3503858  0.67119264 0.81654006\n",
      " 0.43045968 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.17776133\n",
      " 0.85996178 0.9171001  0.90275052 0.66636507 0.39608144 0.89558809\n",
      " 0.82422612 0.17039167 0.28011075 0.82641465 0.43462704 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.15472185 0.83728584 0.8984832  0.86744768\n",
      " 0.58337204 0.0381638  0.24494949 0.41406655 0.07477434 0.\n",
      " 0.         0.78877516 0.58445324 0.07738702 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.10470967\n",
      " 0.54619921 0.88912894 0.80821182 0.67348423 0.25670551 0.\n",
      " 0.         0.         0.         0.         0.         0.73717109\n",
      " 0.53879366 0.22522046 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01469294 0.51694001 0.8532908  0.84247167\n",
      " 0.24319552 0.06088813 0.08808909 0.         0.         0.\n",
      " 0.         0.         0.         0.68967489 0.49485162 0.25100683\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13000301 0.76065082 0.86225595 0.22125459 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.66404791 0.48606787 0.25465826 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.47651189 0.7784253\n",
      " 0.64781243 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.67276109\n",
      " 0.50186124 0.26522606 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.12574922 0.60130604 0.76726627 0.37587352 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.67555472 0.51103827 0.20535038\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.14829932\n",
      " 0.61440388 0.67564826 0.08011407 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02431125\n",
      " 0.42812524 0.68298644 0.37961322 0.01631352 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.15164397 0.60379556 0.62366173\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02496452 0.4489727  0.79477856 0.60151036\n",
      " 0.14195435 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.15939239 0.60658211 0.3916802  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.17303794\n",
      " 0.58905942 0.86928881 0.54151984 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.17291384\n",
      " 0.63779665 0.63328914 0.         0.         0.         0.\n",
      " 0.         0.         0.41448896 0.86097457 0.90790789 0.55402091\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.173018   0.6613801  0.74660128\n",
      " 0.47408582 0.16356035 0.10168781 0.30557608 0.64994561 0.82225559\n",
      " 0.9249454  0.81111254 0.59149027 0.18173311 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.15672245 0.6461687  0.77045276 0.85471661 0.81634985\n",
      " 0.77862211 0.91968997 0.91572127 0.91851569 0.71608444 0.46278291\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.03661374\n",
      " 0.41866508 0.70623937 0.82903913 0.90265708 0.92272722 0.92378273\n",
      " 0.85394509 0.52989523 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.03167892 0.26007691\n",
      " 0.68422177 0.80836034 0.86787383 0.49442199 0.128263   0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "weight_train_array = np.zeros(train_array.shape)\n",
    "\n",
    "for i in range(0, train_array.shape[0]):\n",
    "    weight_train_array[i, 0] = train_array[i, 0]\n",
    "    weight_train_array[i, 1:] = train_array[i, 1:]*weighting_list\n",
    "\n",
    "print(train_array[0, :])\n",
    "print(weight_train_array[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def digit_recognition(sample):\n",
    "\n",
    "    intensities_list = [] #will be filled with average intensity differences for each digit \n",
    "    sample_img = test_array[sample-1, 1:] #create array with intensity values of sample\n",
    "\n",
    "    #subtract avg array from sample array and store as difference array (diff_arr)\n",
    "    for i in range(0,10):\n",
    "        diff_arr = sample_img - avg_digit_arr(train_array, i)\n",
    "        \n",
    "        #turn difference array to difference list\n",
    "        diff_list = []\n",
    "        for j in range(0, 784):\n",
    "            diff_list.append(diff_arr[0, j])\n",
    "\n",
    "        #weight intensities differences\n",
    "        diff_list_weight = np.multiply(diff_list, weighting_list)\n",
    "\n",
    "        #sum all absolute values of difference list and assign to variable intensity_sum\n",
    "        intensity_sum = 0\n",
    "        for k in range(0, len(diff_list_weight)):\n",
    "            diff_list_weight[k] = diff_list_weight[k]**2\n",
    "            diff_list_weight[k] = np.sqrt(diff_list_weight[k])\n",
    "            intensity_sum += diff_list_weight[k]\n",
    "\n",
    "        #append intensities_list by intensity sum\n",
    "        #at the end of for loop, intensites_list contains 1 value for each of the 10 digits\n",
    "        intensities_list.append(intensity_sum)\n",
    "\n",
    "    #select smallest value and return as output\n",
    "    return intensities_list.index(min(intensities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out digit_recognition function\n",
    "print(digit_recognition(12))\n",
    "show_digit(12)\n",
    "print(test_array[11,0]) #note: here we use the index and not the number of the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#√úberpr√ºfung:\n",
    "avg_list = []\n",
    "for i in range(0,10):\n",
    "    avg_list.append(avg_digit_arr(train_array, i))\n",
    "\n",
    "def digit_recognition_fast(sample):\n",
    "    #die geht schneller weil nicht immer die durchschnitsarrays neu berechnet werden\n",
    "    intensities_list = [] \n",
    "    sample_img = test_array[sample-1, 1:] \n",
    "\n",
    "    for i in range(0,10):\n",
    "        diff_arr = sample_img - avg_list[i]\n",
    "        \n",
    "        diff_list = []\n",
    "        for j in range(0, 784):\n",
    "            diff_list.append(diff_arr[0, j])\n",
    "\n",
    "        #weight intensities differences\n",
    "        diff_list_weight = np.multiply(diff_list, weighting_list)\n",
    "\n",
    "        #sum all absolute values of difference list and assign to variable intensity_sum\n",
    "        intensity_sum = 0\n",
    "        for k in range(0, len(diff_list_weight)):\n",
    "            diff_list_weight[k] = diff_list_weight[k]**2\n",
    "            diff_list_weight[k] = np.sqrt(diff_list_weight[k])\n",
    "            intensity_sum += diff_list_weight[k]\n",
    "\n",
    "        #append intensities_list by intensity sum\n",
    "        #at the end of for loop, intensites_list contains 1 value for each of the 10 digits\n",
    "        intensities_list.append(intensity_sum)\n",
    "\n",
    "    #select smallest value and return as output\n",
    "    return intensities_list.index(min(intensities_list))\n",
    "\n",
    "\n",
    "true = 0\n",
    "false = 0\n",
    "\n",
    "for i in range(0, test_array.shape[0]):\n",
    "    if digit_recognition_fast(i+1) == test_array[i, 0]:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "\n",
    "print(f'Anzahl richtig erkannter Digits: {true} \\n\\\n",
    "Anzahl falsch erkannter Digits: {false} \\n\\\n",
    "Richtig: {true/test_array.shape[0]*100} Prozent')\n",
    "#72,05 Prozent mit Durchschnittsdifferenz √ºber die ersten 1000 Bilder\n",
    "#72,06 Prozent mit Durchschnittsdifferenz √ºber die ersten 10000 Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwendung durch Abfrage mit train_array und k = 1\n",
    "def kNN(img, k=4, train = True):\n",
    "    counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "    max_indices = []\n",
    "    dist = knn.distances(train_array, img)\n",
    "\n",
    "    if train == True:\n",
    "        k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1:k+1]\n",
    "    \n",
    "    else:\n",
    "        k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0:k]\n",
    "\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        counter[train_array[k_smallest[i],0]] += 1\n",
    "\n",
    "    for j in range(0, 9):\n",
    "        if counter[j] == max(counter):\n",
    "            max_indices.append(j)\n",
    "\n",
    "    if len(max_indices) == 1:\n",
    "        return max_indices[0]\n",
    "\n",
    "    else:\n",
    "        if train == True:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1]\n",
    "        else:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0]\n",
    "        return train_array[k_smallest,0]\n",
    "        \n",
    "        for i in range(0, len(max_indices)):\n",
    "            if max_indices[i] == 9:\n",
    "                return max_indices[i]\n",
    "        \n",
    "        for i in range(0, len(max_indices)):\n",
    "            if max_indices[i] == 5:\n",
    "                for i in range(0, len(max_indices)):\n",
    "                    if max_indices[i] != 5:\n",
    "                        return max_indices[i]\n",
    "\n",
    "        if train == True:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1]\n",
    "        else:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0]\n",
    "        return train_array[k_smallest,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_kNN_train(s_size, k=5):\n",
    "    true = 0\n",
    "    false = 0\n",
    "    false_pred = []\n",
    "\n",
    "    for i in range(0, s_size):\n",
    "        result_kNN = kNN(train_array[29500 + i, 1:], k, train=True)\n",
    "        if result_kNN == train_array[29500 + i, 0]:\n",
    "            true += 1\n",
    "        else:\n",
    "            false += 1\n",
    "            \n",
    "    return print(f'Anzahl richtig erkannter Digits: {true}\\n\\\n",
    "Anzahl falsch erkannter Digits: {false}\\n\\\n",
    "\\nAnteil richtiger Vorhersagen: {(true/s_size)*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Functions.PCA as pca\n",
    "from Functions.kNN import kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_array, z_image = pca.z_transformation(train_array[:, 1:], test_array[3, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_arr, pca_img = pca.PCA(z_array, z_image, num_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN(pca_arr, pca_img, k = , train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(PCs_arr, PCs_img, k, train = True):\n",
    "   \n",
    "   #Distance calculation\n",
    "    arr_rows = PCs_arr.shape[0]\n",
    "    img_dot = (PCs_img**2).sum(axis=0)*np.ones(shape=(1,arr_rows))\n",
    "    arr_dot = (PCs_arr[:, :]**2).sum(axis=1)\n",
    "    dist_arr =  np.sqrt(img_dot + arr_dot - 2*np.dot(PCs_img, PCs_arr[:, :].T))\n",
    "    dist = dist_arr.tolist()[0]\n",
    "    \n",
    "    #Sorting\n",
    "    counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "    max_indices = []\n",
    "    \n",
    "    if train == True:\n",
    "        k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1:k+1]\n",
    "    \n",
    "    else:\n",
    "        k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0:k]\n",
    "\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        counter[train_array[k_smallest[i],0]] += 1\n",
    "\n",
    "    for j in range(0, 9):\n",
    "        if counter[j] == max(counter):\n",
    "            max_indices.append(j)\n",
    "            \n",
    "\n",
    "    if len(max_indices) == 1:\n",
    "        return max_indices[0]\n",
    "\n",
    "    else:\n",
    "        if train == True:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1]\n",
    "        else:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0]\n",
    "        return train_array[k_smallest,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN(pca_arr, pca_img, k = 3, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_kNN_test(s_size, k=5):\n",
    "    true = 0\n",
    "    false = 0\n",
    "\n",
    "    for i in range(0, s_size):\n",
    "\n",
    "        z_array, z_image = pca.z_transformation(train_array[:, 1:], test_array[i, 1:])\n",
    "        pca_arr, pca_img = pca.PCA(z_array, z_image, num_components=30)\n",
    "\n",
    "\n",
    "        result_kNN = kNN(pca_arr, pca_img, k = 5, train=False)\n",
    "        if result_kNN == test_array[i, 0]:\n",
    "            true += 1\n",
    "        else:\n",
    "            false += 1\n",
    "\n",
    "    return print(f'Anzahl richtig erkannter Digits: {true}\\n\\\n",
    "Anzahl falsch erkannter Digits: {false}\\n\\\n",
    "\\nAnteil richtiger Vorhersagen: {(true/s_size)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl richtig erkannter Digits: 145\n",
      "Anzahl falsch erkannter Digits: 5\n",
      "\n",
      "Anteil richtiger Vorhersagen: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "validation_kNN_test(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl richtig erkannter Digits: 975\n",
      "Anzahl falsch erkannter Digits: 25\n",
      "\n",
      "Anteil richtiger Vorhersagen: 97.5%\n"
     ]
    }
   ],
   "source": [
    "#Idee zur weiteren Verbesserung: Schauen welche Zahlen am h√§ufigsten f√§lschlicherweise vorhergesagt werden. Vergleich mit Durchschnittszahl. Gewichtung verschiedener Faktoren.\n",
    "\n",
    "#Validation mit Trainingsdatensatz und k=1 bei mehreren Maxima (Zeile 29500 - 30500)\n",
    "#k=1 -> 97,3%\n",
    "#k=2 -> 97,3%\n",
    "#k=3 -> 97,6%\n",
    "#k=4 -> 97,6%\n",
    "#k=5 -> 97,4%\n",
    "#k=6 -> 97,2%\n",
    "validation_kNN_train(1000, k = 4)\n",
    "#97,4% mit -> if 9 elif 1 elif 2 -> kNN = 1\n",
    "#97,7% mit -> if 9 elif 1 elif 2 -> kNN = 1 + Pixel-Gewichtung\n",
    "#97,6% mit -> if 9 elif 5 -> kNN = 1 + Pixel-Gewichtung\n",
    "#97,4% mit -> if 9 -> kNN = 1 + Pixel-Gewichtung\n",
    "#97,4% mit -> kNN = 1 + Pixel-Gewichtung\n",
    "#97,5% mit -> kNN = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminwehnert/digitrecognition/2022-topic-01-team-02/Benni.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminwehnert/digitrecognition/2022-topic-01-team-02/Benni.ipynb#ch0000027?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(false_pred)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminwehnert/digitrecognition/2022-topic-01-team-02/Benni.ipynb#ch0000027?line=1'>2</a>\u001b[0m true\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "len(false_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 106, 3, 2, 3, 4, 1, 2, 1, 0]\n",
      "[1, 3, 3, 2, 3, 6, 2, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#welche Zahlen wie oft nicht erkannt werden bei Train mit Pixelgewichtung, mit k=1 bei mehreren Maxima (Zeile 29500 - 30500)\n",
    "# -> [2, 1, 1, 5, 1, 2, 0, 4, 1, 6]\n",
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "for i in range(0, len(false_ind)):\n",
    "    j = false_ind[i]\n",
    "    counter[j] += 1\n",
    "print(counter)\n",
    "\n",
    "#welche Zahlen wie oft f√§lschlicherweise berechnet werden bei Train mit Pixelgewichtung, mit k=1 bei mehreren Maxima (Zeile 29500 - 30500)\n",
    "# -> [1, 3, 3, 2, 3, 6, 2, 2, 1, 0]\n",
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "for i in range(0, len(false_pred)):\n",
    "    j = false_pred[i]\n",
    "    counter[j] += 1\n",
    "print(counter)\n",
    "\n",
    "#interessant sind hier vor allem die Zahlen bei denen es starke Abweichungen gibt. Also besonders 5 und 9. -> if 9 elif 5 -> kNN = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = np.array([[1,2,3],[3,2,5],[9,0,2]])\n",
    "print(x)\n",
    "min1 = np.argwhere(x == np.min(x[:,0]))\n",
    "min2 = min1[0]\n",
    "min2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "541128196ab36f0af3e9e280f838c1b088f9a4d7f344cac0adf931df1b356af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('digit_recognitoin_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
