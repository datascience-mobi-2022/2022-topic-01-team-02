{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Functions import kNN as knn\n",
    "#load data\n",
    "train_digits = pd.read_csv(\"data/mnist_train.csv\")\n",
    "test_digits = pd.read_csv(\"data/mnist_test.csv\")\n",
    "#convert pandas Data Frame to Numpy Array\n",
    "train_array = train_digits.to_numpy()\n",
    "test_array = test_digits.to_numpy()\n",
    "# Datensatz hat 59999 Zeilen\n",
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show image \n",
    "def return_label(sample):\n",
    "    return train_array[sample-1, 0]\n",
    "\n",
    "def show_digit(sample):\n",
    "    img = train_array[sample-1, 1:]\n",
    "    img.shape = (28,28)\n",
    "    plt.imshow(img, 'gray')\n",
    "\n",
    "print(return_label(79))\n",
    "show_digit(79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute average intensities of all rows describing the same number\n",
    "#imshow as output\n",
    "def avg_digit_img(dat, digit):\n",
    "\n",
    "    #create list with rowindex for given digit\n",
    "    list_digit = []\n",
    "    for i in range(0, dat.shape[0]):\n",
    "        if dat[i, 0] == digit:\n",
    "            list_digit.append(i)\n",
    "\n",
    "    #create np array filled with zeros in shape flat image\n",
    "    avg = np.zeros((1,784))\n",
    "    \n",
    "    #sum up intensities from all selected images for every pixel\n",
    "    for j in range(0, len(list_digit)):\n",
    "        avg += dat[list_digit[j], 1:]\n",
    "    #shape image\n",
    "    avg.shape = (28,28)\n",
    "    #divide by number of selected pictures for average intensity value\n",
    "    avg /= len(list_digit)\n",
    "\n",
    "    #show image and colorbar\n",
    "    plt.imshow(avg, 'gray')\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare sample image with averaged images pixel by pixel\n",
    "#select digit with lowest difference in intensity (output)\n",
    "def digit_recognition(sample):\n",
    "\n",
    "    intensities_list = [] #will be filled with average intensity differences for each digit \n",
    "    sample_img = test_array[sample-1, 1:] #create array with intensity values of sample\n",
    "\n",
    "    #subtract avg array from sample array and store as difference array (diff_arr)\n",
    "    for i in range(0,10):\n",
    "        diff_arr = sample_img - avg_digit_arr(train_array, i)\n",
    "        \n",
    "        #turn difference array to difference list\n",
    "        diff_list = []\n",
    "        for j in range(0, 784):\n",
    "            diff_list.append(diff_arr[0, j])\n",
    "\n",
    "        #sum all absolute values of difference list and assign to variable intensity_sum\n",
    "        intensity_sum = 0\n",
    "        for k in range(0, len(diff_list)):\n",
    "            diff_list[k] = diff_list[k]**2\n",
    "            diff_list[k] = np.sqrt(diff_list[k])\n",
    "            intensity_sum += diff_list[k]\n",
    "\n",
    "        #append intensities_list by intensity sum\n",
    "        #at the end of for loop, intensites_list contains 1 value for each of the 10 digits\n",
    "        intensities_list.append(intensity_sum)\n",
    "\n",
    "    #select smallest value and return as output\n",
    "    return intensities_list.index(min(intensities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intensit√§tsdifferenzen zwischen n-tem Pixel von allen Bildern aufaddieren\n",
    "intensities_diff = np.zeros((1, 784))\n",
    "for i in range(0, 10000):\n",
    "    for j in range(0, 10000):\n",
    "        if i != j:\n",
    "            intensities_diff += np.sqrt((train_array[i, 1:785] - train_array[j, 1:785])**2)\n",
    "\n",
    "#array in liste\n",
    "intensities_diff_list = []\n",
    "for k in range(0, 784):\n",
    "    intensities_diff_list.append(intensities_diff[0, k])\n",
    "\n",
    "#anteile jedes pixels berechnen\n",
    "weighting_list = []\n",
    "for m in range(0,784):\n",
    "    weighting_list.append(intensities_diff_list[m]/sum(intensities_diff_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def digit_recognition(sample):\n",
    "\n",
    "    intensities_list = [] #will be filled with average intensity differences for each digit \n",
    "    sample_img = test_array[sample-1, 1:] #create array with intensity values of sample\n",
    "\n",
    "    #subtract avg array from sample array and store as difference array (diff_arr)\n",
    "    for i in range(0,10):\n",
    "        diff_arr = sample_img - avg_digit_arr(train_array, i)\n",
    "        \n",
    "        #turn difference array to difference list\n",
    "        diff_list = []\n",
    "        for j in range(0, 784):\n",
    "            diff_list.append(diff_arr[0, j])\n",
    "\n",
    "        #weight intensities differences\n",
    "        diff_list_weight = np.multiply(diff_list, weighting_list)\n",
    "\n",
    "        #sum all absolute values of difference list and assign to variable intensity_sum\n",
    "        intensity_sum = 0\n",
    "        for k in range(0, len(diff_list_weight)):\n",
    "            diff_list_weight[k] = diff_list_weight[k]**2\n",
    "            diff_list_weight[k] = np.sqrt(diff_list_weight[k])\n",
    "            intensity_sum += diff_list_weight[k]\n",
    "\n",
    "        #append intensities_list by intensity sum\n",
    "        #at the end of for loop, intensites_list contains 1 value for each of the 10 digits\n",
    "        intensities_list.append(intensity_sum)\n",
    "\n",
    "    #select smallest value and return as output\n",
    "    return intensities_list.index(min(intensities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out digit_recognition function\n",
    "print(digit_recognition(12))\n",
    "show_digit(12)\n",
    "print(test_array[11,0]) #note: here we use the index and not the number of the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#√úberpr√ºfung:\n",
    "avg_list = []\n",
    "for i in range(0,10):\n",
    "    avg_list.append(avg_digit_arr(train_array, i))\n",
    "\n",
    "def digit_recognition_fast(sample):\n",
    "    #die geht schneller weil nicht immer die durchschnitsarrays neu berechnet werden\n",
    "    intensities_list = [] \n",
    "    sample_img = test_array[sample-1, 1:] \n",
    "\n",
    "    for i in range(0,10):\n",
    "        diff_arr = sample_img - avg_list[i]\n",
    "        \n",
    "        diff_list = []\n",
    "        for j in range(0, 784):\n",
    "            diff_list.append(diff_arr[0, j])\n",
    "\n",
    "        #weight intensities differences\n",
    "        diff_list_weight = np.multiply(diff_list, weighting_list)\n",
    "\n",
    "        #sum all absolute values of difference list and assign to variable intensity_sum\n",
    "        intensity_sum = 0\n",
    "        for k in range(0, len(diff_list_weight)):\n",
    "            diff_list_weight[k] = diff_list_weight[k]**2\n",
    "            diff_list_weight[k] = np.sqrt(diff_list_weight[k])\n",
    "            intensity_sum += diff_list_weight[k]\n",
    "\n",
    "        #append intensities_list by intensity sum\n",
    "        #at the end of for loop, intensites_list contains 1 value for each of the 10 digits\n",
    "        intensities_list.append(intensity_sum)\n",
    "\n",
    "    #select smallest value and return as output\n",
    "    return intensities_list.index(min(intensities_list))\n",
    "\n",
    "\n",
    "true = 0\n",
    "false = 0\n",
    "\n",
    "for i in range(0, test_array.shape[0]):\n",
    "    if digit_recognition_fast(i+1) == test_array[i, 0]:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "\n",
    "print(f'Anzahl richtig erkannter Digits: {true} \\n\\\n",
    "Anzahl falsch erkannter Digits: {false} \\n\\\n",
    "Richtig: {true/test_array.shape[0]*100} Prozent')\n",
    "#72,05 Prozent mit Durchschnittsdifferenz √ºber die ersten 1000 Bilder\n",
    "#72,06 Prozent mit Durchschnittsdifferenz √ºber die ersten 10000 Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwendung durch Abfrage mit train_array und k = 1\n",
    "def kNN(img, k=4, train = True):\n",
    "    counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "    max_indices = []\n",
    "    dist = knn.distances(train_array, img)\n",
    "\n",
    "    if train == True:\n",
    "        k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1:k+1]\n",
    "    \n",
    "    else:\n",
    "        k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0:k]\n",
    "\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        counter[train_array[k_smallest[i],0]] += 1\n",
    "\n",
    "    for j in range(0, 9):\n",
    "        if counter[j] == max(counter):\n",
    "            max_indices.append(j)\n",
    "\n",
    "    if len(max_indices) == 1:\n",
    "        return max_indices[0]\n",
    "\n",
    "    else:\n",
    "        dist = knn.distances(train_array, img)\n",
    "        if train == True:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[1]\n",
    "        else:\n",
    "            k_smallest = sorted(range(len(dist)), key = lambda sub: dist[sub])[0]\n",
    "        return train_array[k_smallest,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_kNN_train(s_size, k=5):\n",
    "    true = 0\n",
    "    false = 0\n",
    "    false_pred = []\n",
    "\n",
    "    for i in range(0, s_size):\n",
    "        result_kNN = kNN(train_array[29500 + i, 1:], k, train=True)\n",
    "        if result_kNN == train_array[29500 + i, 0]:\n",
    "            true += 1\n",
    "        else:\n",
    "            false += 1\n",
    "            false_pred.append(result_kNN)\n",
    "    return false_pred\n",
    "    return print(f'Anzahl richtig erkannter Digits: {true}\\n\\\n",
    "Anzahl falsch erkannter Digits: {false}\\n\\\n",
    "\\nAnteil richtiger Vorhersagen: {(true/s_size)*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 9, 8, 1, 2, 5, 5, 6, 5, 3, 6, 1, 7, 7, 5, 5, 1, 0, 4, 3, 1, 6, 6, 8]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Idee zur weiteren Verbesserung: Schauen welche Zahlen am h√§ufigsten f√§lschlicherweise vorhergesagt werden. Vergleich mit Durchschnittszahl. Gewichtung verschiedener Faktoren.\n",
    "\n",
    "#Validation mit Trainingsdatensatz und k=1 bei mehreren Maxima (Zeile 29500 - 30500)\n",
    "#k=1 -> 97,3%\n",
    "#k=2 -> 97,3%\n",
    "#k=3 -> 97,6%\n",
    "#k=4 -> 97,6%\n",
    "#k=5 -> 97,4%\n",
    "#k=6 -> 97,2%\n",
    "false_pred = validation_kNN_train(1000, k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 2, 2, 1, 5, 4, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#welche Zahlen wie oft nicht erkannt werden bei Train mit k=1 bei mehreren Maxima (Zeile 29500 - 30500)\n",
    "# -> [0, 1, 5, 1, 0, 6, 2, 4, 3, 6]\n",
    "\n",
    "#welche Zahlen wie oft f√§lschlicherweise berechnet werden bei Train mit k=1 bei mehreren Maxima (Zeile 29500 - 30500)\n",
    "# -> [1, 5, 2, 2, 1, 5, 4, 2, 2, 1]\n",
    "\n",
    "#interessant sind hier vor allem die Zahlen bei denen es starke Abweichungen gibt. Also besonders 1, 2, 9. -> if 9 elif 1 elif 2 -> kNN = 1\n",
    "\n",
    "counter = [0,0,0,0,0,0,0,0,0,0]\n",
    "for i in range(0, len([1, 2, 9, 8, 1, 2, 5, 5, 6, 5, 3, 6, 1, 7, 7, 5, 5, 1, 0, 4, 3, 1, 6, 6, 8])):\n",
    "    j = [1, 2, 9, 8, 1, 2, 5, 5, 6, 5, 3, 6, 1, 7, 7, 5, 5, 1, 0, 4, 3, 1, 6, 6, 8][i]\n",
    "    counter[j] += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = np.array([[1,2,3],[3,2,5],[9,0,2]])\n",
    "print(x)\n",
    "min1 = np.argwhere(x == np.min(x[:,0]))\n",
    "min2 = min1[0]\n",
    "min2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "541128196ab36f0af3e9e280f838c1b088f9a4d7f344cac0adf931df1b356af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('digit_recognitoin_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
